import numpy as np
from sklearn.metrics.pairwise import cosine_similarity
import random
import itertools

# Define user profiles, product categories, and popularity scores
user_profiles = {
    'user_1' {'electronics' 0.8, 'fashion' 0.4},
    'user_2' {'electronics' 0.6, 'fashion' 0.8},
    # Add more user profiles...
}

product_categories = ['electronics', 'fashion', 'home', 'books', 'sports']
product_ids = ['product_' + str(i) for i in range(1, 101)]  # Generate 100 product IDs

product_attributes = {product_id {'category' random.choice(product_categories)} for product_id in product_ids}
product_popularity = {product_id np.random.randint(250, 500) for product_id in product_ids}

# Generate random user-product interactions
user_product_interaction = {}
for user_id in user_profiles
    interactions = {}
    for product_id in product_ids
        interactions[product_id] = np.random.choice([0, 1], p=[0.8, 0.2])
    user_product_interaction[user_id] = interactions

# Generate more users and interactions
num_additional_users = 50
for i in range(3, 3 + num_additional_users)  # Generate user_3 to user_52
    user_id = f'user_{i}'
    user_profiles[user_id] = {category np.random.uniform(0, 1) for category in product_categories}
    interactions = {}
    for product_id in product_ids
        interactions[product_id] = np.random.choice([0, 1], p=[0.7, 0.3])
    user_product_interaction[user_id] = interactions

# Calculate User Similarity
num_categories = len(product_categories)
user_similarity_matrix = np.zeros((len(user_profiles), len(user_profiles)))

for i, (user1, profile1) in enumerate(user_profiles.items())
    for j, (user2, profile2) in enumerate(user_profiles.items())
        profile1_values = np.array([profile1.get(category, 0) for category in product_categories]).reshape(1, -1)
        profile2_values = np.array([profile2.get(category, 0) for category in product_categories]).reshape(1, -1)
        user_similarity_matrix[i, j] = cosine_similarity(profile1_values, profile2_values)[0, 0]

# Collaborative Filtering
predicted_rankings_collaborative = {}
target_user = 'user_1'  # Change this to the user for whom you're making predictions
target_user_index = list(user_profiles.keys()).index(target_user)

for product in product_attributes
    product_similarity_scores = [
        user_similarity_matrix[target_user_index, list(user_profiles.keys()).index(user)]
        for user, interaction in user_product_interaction.items()
        if interaction[product] == 1
    ]
    predicted_rankings_collaborative[product] = np.mean(product_similarity_scores) if product_similarity_scores else 0

# Content-Based Filtering
predicted_rankings_content_based = {}
for product, attributes in product_attributes.items()
    product_category = attributes['category']
    product_similarity_scores = [
        user_profiles[user].get(product_category, 0)
        for user, interaction in user_product_interaction.items()
        if interaction[product] == 1
    ]
    predicted_rankings_content_based[product] = np.mean(product_similarity_scores) if product_similarity_scores else 0

# Hyperparameter tuning using grid search
weight_collaborative_values = np.linspace(0, 1, num=10)
weight_content_values = 1 - weight_collaborative_values
tuning_results = {}

for weight_collaborative, weight_content in itertools.product(weight_collaborative_values, weight_content_values)
    predicted_rankings_combined = {}

    for user_id in user_profiles
        combined_predictions = {}

        for product_id in product_attributes
            collaborative_prediction = predicted_rankings_collaborative.get(product_id, 0)
            content_based_prediction = predicted_rankings_content_based.get(product_id, 0)
            combined_prediction = weight_collaborative  collaborative_prediction + weight_content  content_based_prediction
            combined_predictions[product_id] = combined_prediction

        predicted_rankings_combined[user_id] = combined_predictions

    # Evaluate Metrics for Combined Predictions
    K = 5
    precision_sum = 0
    recall_sum = 0
    map_sum = 0

    for user_id, interactions in user_product_interaction.items()
        actual_relevant_items = [product_id for product_id, interaction in interactions.items() if interaction == 1]
        predicted_rankings_for_user = sorted(predicted_rankings_combined[user_id].items(), key=lambda x x[1], reverse=True)[K]
        predicted_relevant_items = [product_id for product_id, _ in predicted_rankings_for_user]

        true_positives = len(set(actual_relevant_items) & set(predicted_relevant_items))
        precision = true_positives  K
        recall = true_positives  len(actual_relevant_items)

        average_precision = 0
        relevant_count = 0

        for i, (product_id, _) in enumerate(predicted_rankings_for_user, start=1)
            if product_id in actual_relevant_items
                relevant_count += 1
                average_precision += relevant_count  i

        if len(actual_relevant_items)  0
            average_precision = len(actual_relevant_items)

        precision_sum += precision
        recall_sum += recall
        map_sum += average_precision

    total_users = len(user_profiles)
    average_map_at_k = map_sum  total_users

    tuning_results[(weight_collaborative, weight_content)] = average_map_at_k

# Find the best hyperparameters
best_hyperparameters = max(tuning_results, key=tuning_results.get)
best_average_map_at_k = tuning_results[best_hyperparameters]

print(Best Hyperparameters, best_hyperparameters)
print(Best Mean Average Precision, best_average_map_at_k)

# Calculate Coverage
all_items = set(product_ids)
recommended_items = set()
for user_id in user_profiles
    recommended_items.update(predicted_rankings_combined[user_id].keys())
coverage = len(recommended_items)  len(all_items)

# Calculate Diversity (using Jaccard similarity between recommended item sets)
diversity_scores = []
for user_id in user_profiles
    recommended_items_user = set(predicted_rankings_combined[user_id].keys())
    diversity = len(recommended_items_user & recommended_items)  len(recommended_items_user  recommended_items)
    diversity_scores.append(diversity)
average_diversity = np.mean(diversity_scores)

# Print the metrics
print(Coverage, coverage)
print(Average Diversity, average_diversity)